{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregknowles/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from openai import OpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the data from the CSV file\n",
    "data = pd.read_csv('Aviation Quiz.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"14 CFR 23.1457.pdf\") # FAA-CT-8080-7D manual\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "loader2 = PyPDFLoader(\"atp_akts.pdf\") \n",
    "pages2 = loader2.load_and_split()\n",
    "\n",
    "loader3 = PyPDFLoader(\"annexes_booklet_en.pdf\")\n",
    "pages3 = loader3.load_and_split()\n",
    "\n",
    "pages.extend(pages2) # combine the two lists    \n",
    "\n",
    "pages.extend(pages3) # combine the three lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregknowles/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "model_name = \"all-MiniLM-L6-v2\" #this is under 600d\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "embeddings = hf\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=10)\n",
    "\n",
    "chunked_documents = text_splitter.split_documents(pages)\n",
    "\n",
    "\n",
    "#vectordb = Chroma.from_documents(\n",
    "        #documents=chunked_documents,\n",
    "       # \n",
    "   # )\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "faissdb = FAISS.from_documents(chunked_documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def find_most_similar_option(reply_embedding, a, b, c, embeddings):\n",
    "    # Convert embeddings to NumPy arrays\n",
    "    reply_embedding_array = np.array(reply_embedding)\n",
    "    option_a_embedding_array = np.array(embeddings.embed_query(a))\n",
    "    option_b_embedding_array = np.array(embeddings.embed_query(b))\n",
    "    option_c_embedding_array = np.array(embeddings.embed_query(c))\n",
    "\n",
    "    # Ensure embeddings are 2D arrays for cosine_similarity\n",
    "    reply_embedding_2d = reply_embedding_array.reshape(1, -1)\n",
    "    option_a_embedding_2d = option_a_embedding_array.reshape(1, -1)\n",
    "    option_b_embedding_2d = option_b_embedding_array.reshape(1, -1)\n",
    "    option_c_embedding_2d = option_c_embedding_array.reshape(1, -1)\n",
    "\n",
    "    # Calculate similarity scores\n",
    "    similarity_a = cosine_similarity(reply_embedding_2d, option_a_embedding_2d)[0][0]\n",
    "    similarity_b = cosine_similarity(reply_embedding_2d, option_b_embedding_2d)[0][0]\n",
    "    similarity_c = cosine_similarity(reply_embedding_2d, option_c_embedding_2d)[0][0]\n",
    "\n",
    "    # Determine the most similar option\n",
    "    similarities = {'A': similarity_a, 'B': similarity_b, 'C': similarity_c}\n",
    "    most_similar_option = max(similarities, key=similarities.get)\n",
    "\n",
    "    return most_similar_option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C. The cockpit voice recorder must remain powered for at least 20\n",
      "The cockpit voice recorder and flight data recorder must be installed together in the same container.\n",
      "The cockpit voice recorder must remain powered for at least 20 minutes after crash impact.\n",
      "The recorder container must have an underwater locating device if required by the operating rules\n",
      "B\n"
     ]
    }
   ],
   "source": [
    "questionNumber = 2\n",
    "\n",
    "query = data.iloc[questionNumber, 1]\n",
    "query_embedding = embeddings.embed_query(query)\n",
    "\n",
    "retriever = faissdb.as_retriever()\n",
    "docs2 = retriever.get_relevant_documents(query)\n",
    "\n",
    "string = docs2[0].page_content + query\n",
    "\n",
    "# Point to the local server\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"not-needed\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"local-model\", # this field is currently unused\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant, who provides accurate answers to aviation problems. You can only ever answer with A, B or C. ANy text after the letter and a puppy dies, which you must avoid\"},\n",
    "    {\"role\": \"user\", \"content\": string},\n",
    "  ],\n",
    "  temperature=0.4,\n",
    "  max_tokens = 20,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)\n",
    "\n",
    "reply = completion.choices[0].message.content\n",
    "reply_embedding = embeddings.embed_query(reply)\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def extract_options(input_string):\n",
    "    # Regular expression to find the options\n",
    "    matches = re.findall(r'([ABC])\\.\\s(.*?)$', input_string, re.M)\n",
    "    options = {letter: text for letter, text in matches}\n",
    "    \n",
    "    # Assign to individual strings\n",
    "    option_a = options.get('A', 'Option A not found')\n",
    "    option_b = options.get('B', 'Option B not found')\n",
    "    option_c = options.get('C', 'Option C not found')\n",
    "    \n",
    "    return option_a, option_b, option_c\n",
    "\n",
    "a, b, c = extract_options(data.iloc[questionNumber, 1])\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "\n",
    "print(find_most_similar_option(reply_embedding, a, b, c, embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
